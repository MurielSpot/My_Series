{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.data.Dataset.from_generator的用法\n",
    "\n",
    "参考：\n",
    "- https://www.jianshu.com/p/d80ea5d73446"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建数据生成的函数\n",
    "def data_generator():\n",
    "    dataset = np.array(range(5))\n",
    "    for d in dataset:\n",
    "        print(\"in func, data:\",d)\n",
    "        yield d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\shaw\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:429: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, use\n",
      "    tf.py_function, which takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "shapes=(tf.TensorShape([]))\n",
    "types=(tf.int32)\n",
    "dataset = tf.data.Dataset.from_generator(data_generator, output_shapes=shapes, output_types=types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in func, data: 0\n",
      "Batch No. 0: 0\n",
      "in func, data: 1\n",
      "Batch No. 1: 1\n",
      "in func, data: 2\n",
      "Batch No. 2: 2\n",
      "in func, data: 3\n",
      "Batch No. 3: 3\n",
      "in func, data: 4\n",
      "Batch No. 4: 4\n",
      "end!\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "API 支持以下四种 iterator，复杂程度递增：\n",
    "    one-shot\n",
    "    initializable\n",
    "    reinitializable\n",
    "    feedable\n",
    "    one-shot\n",
    "one-shot iterator 谁最简单的一种 iterator，仅支持对整个数据集访问一遍，不需要显式的初始化。\n",
    "one-shot iterator 不支参数化。\n",
    "'''\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "one_element = iterator.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    try:\n",
    "        batch_num=0\n",
    "        while True:\n",
    "            one_batch = sess.run(one_element)\n",
    "            print('Batch No. %d:' % batch_num,one_batch)\n",
    "            batch_num+=1\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        print('end!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in func, data: 0\n",
      "Batch No. 0: 0\n",
      "in func, data: 1\n",
      "Batch No. 1: 1\n",
      "in func, data: 2\n",
      "Batch No. 2: 2\n",
      "in func, data: 3\n",
      "Batch No. 3: 3\n",
      "in func, data: 4\n",
      "Batch No. 4: 4\n",
      "in func, data: 0\n",
      "Batch No. 5: 0\n",
      "in func, data: 1\n",
      "Batch No. 6: 1\n",
      "in func, data: 2\n",
      "Batch No. 7: 2\n",
      "in func, data: 3\n",
      "Batch No. 8: 3\n",
      "in func, data: 4\n",
      "Batch No. 9: 4\n",
      "end!\n"
     ]
    }
   ],
   "source": [
    "# epoch=2，即repeat两次\n",
    "dataset=dataset.repeat(2)\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "one_element = iterator.get_next()\n",
    " \n",
    "with tf.Session() as sess:\n",
    "    try:\n",
    "        batch_num=0\n",
    "        while True:\n",
    "            one_batch = sess.run(one_element)\n",
    "            print('Batch No. %d:' % batch_num,one_batch)\n",
    "            batch_num+=1\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        print('end!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in func, data: 0\n",
      "in func, data: 1\n",
      "in func, data: 2\n",
      "in func, data: 3\n",
      "in func, data: 4\n",
      "in func, data: 0\n",
      "in func, data: 1\n",
      "in func, data: 2\n",
      "Batch No. 0: 2\n",
      "in func, data: 3\n",
      "Batch No. 1: 0\n",
      "in func, data: 4\n",
      "Batch No. 2: 2\n",
      "Batch No. 3: 0\n",
      "Batch No. 4: 3\n",
      "Batch No. 5: 4\n",
      "Batch No. 6: 1\n",
      "Batch No. 7: 3\n",
      "Batch No. 8: 4\n",
      "Batch No. 9: 1\n",
      "end!\n"
     ]
    }
   ],
   "source": [
    "# buffer 大小设置为8，打乱 dataset\n",
    "dataset=dataset.shuffle(8)\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "one_element = iterator.get_next()\n",
    " \n",
    "with tf.Session() as sess:\n",
    "    try:\n",
    "        batch_num=0\n",
    "        while True:\n",
    "            one_batch = sess.run(one_element)\n",
    "            print('Batch No. %d:' % batch_num,one_batch)\n",
    "            batch_num+=1\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        print('end!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in func, data: 0\n",
      "in func, data: 1\n",
      "in func, data: 2\n",
      "in func, data: 3\n",
      "in func, data: 4\n",
      "in func, data: 0\n",
      "in func, data: 1\n",
      "in func, data: 2\n",
      "in func, data: 3\n",
      "in func, data: 4\n",
      "Batch No. 0: [0]\n",
      "Batch No. 1: [1 4 2]\n",
      "Batch No. 2: [0 3 3]\n",
      "Batch No. 3: [1 2 4]\n",
      "end!\n"
     ]
    }
   ],
   "source": [
    "# 设置 batch size 为3\n",
    "dataset = dataset.batch(3)\n",
    "dataset=dataset.shuffle(10)\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "one_element = iterator.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    try:\n",
    "        batch_num=0\n",
    "        while True:\n",
    "            one_batch = sess.run(one_element)\n",
    "            print('Batch No. %d:' % batch_num,one_batch)\n",
    "            batch_num+=1\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        print('end!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch No. 0: [6 7 8]\n",
      "Batch No. 1: [0 1 2]\n",
      "Batch No. 2: [3 4 5]\n",
      "end!\n"
     ]
    }
   ],
   "source": [
    "# 指定range\n",
    "dataset = tf.data.Dataset.range(9)\n",
    "dataset = dataset.batch(3)\n",
    "dataset=dataset.shuffle(10)\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "one_element = iterator.get_next()\n",
    " \n",
    "with tf.Session() as sess:\n",
    "    try:\n",
    "        batch_num=0\n",
    "        while True:\n",
    "            one_batch = sess.run(one_element)\n",
    "            print('Batch No. %d:' % batch_num,one_batch)\n",
    "            batch_num+=1\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        print('end!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializable iterator\n",
    "\n",
    "要求在使用之前显式的通过调用iterator.initializer操作初始化，这使得在定义数据集时可以结合tf.placeholder传入参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\shaw\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:1419: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "(1) 0\n",
      "(1) 1\n",
      "(1) 2\n",
      "(1) 3\n",
      "(1) 4\n",
      "(2) 0\n",
      "(2) 1\n",
      "(2) 2\n",
      "(2) 3\n",
      "(2) 4\n",
      "(2) 5\n",
      "(2) 6\n"
     ]
    }
   ],
   "source": [
    "# Initializable iterator\n",
    "max_value = tf.placeholder(tf.int64, shape=[])\n",
    "dataset = tf.data.Dataset.range(max_value)\n",
    "iterator = dataset.make_initializable_iterator()\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "sess=tf.Session()\n",
    "# Initialize an iterator over a dataset with 5 elements.\n",
    "sess.run(iterator.initializer, feed_dict={max_value: 5})\n",
    "for i in range(5):\n",
    "    value = sess.run(next_element)\n",
    "    assert i == value\n",
    "    print(\"(1)\",i)\n",
    "\n",
    "# Initialize the same iterator over a dataset with 100 elements.\n",
    "sess.run(iterator.initializer, feed_dict={max_value: 100})\n",
    "for i in range(7):\n",
    "    value = sess.run(next_element)\n",
    "    assert i == value\n",
    "    print(\"(2)\",i)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reinitializable iterator \n",
    "\n",
    "可以被不同的 dataset 对象初始化，\n",
    "比如对于训练集进行了shuffle的操作，对于验证集则没有处理，通常这种情况会使用两个具有相同结构的dataset对象"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_dataset.output_types <dtype: 'int64'>\n",
      "training_dataset.output_shapes ()\n",
      "WARNING:tensorflow:From c:\\users\\shaw\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:358: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "epoch [0] train: 7\n",
      "epoch [0] train: 2\n",
      "epoch [0] train: 3\n",
      "epoch [0] val: 0\n",
      "epoch [0] val: 1\n",
      "epoch [1] train: -9\n",
      "epoch [1] train: 10\n",
      "epoch [1] train: 6\n",
      "epoch [1] val: 0\n",
      "epoch [1] val: 1\n"
     ]
    }
   ],
   "source": [
    "# Define training and validation datasets with the same structure.\n",
    "training_dataset = tf.data.Dataset.range(3).map(lambda x: x + tf.random_uniform([], -10, 10, tf.int64))\n",
    "validation_dataset = tf.data.Dataset.range(2)\n",
    "\n",
    "# A reinitializable iterator is defined by its structure. We could use the\n",
    "# `output_types` and `output_shapes` properties of either `training_dataset`\n",
    "# or `validation_dataset` here, because they are compatible.\n",
    "print(\"training_dataset.output_types\",training_dataset.output_types)\n",
    "print(\"training_dataset.output_shapes\",training_dataset.output_shapes)\n",
    "iterator = tf.data.Iterator.from_structure(training_dataset.output_types,training_dataset.output_shapes)\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "training_init_op = iterator.make_initializer(training_dataset)\n",
    "validation_init_op = iterator.make_initializer(validation_dataset)\n",
    "\n",
    "# Run 20 epochs in which the training dataset is traversed, followed by the\n",
    "# validation dataset.\n",
    "sess=tf.Session()\n",
    "for i in range(2):\n",
    "    # Initialize an iterator over the training dataset.\n",
    "    sess.run(training_init_op)\n",
    "    for _ in range(3):\n",
    "        output=sess.run(next_element)\n",
    "        print(\"epoch [%d] train:\"%(i),output)\n",
    "\n",
    "  # Initialize an iterator over the validation dataset.\n",
    "    sess.run(validation_init_op)\n",
    "    for _ in range(2):\n",
    "        output=sess.run(next_element)\n",
    "        print(\"epoch [%d] val:\"%(i),output)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### feedable iterator\n",
    "可以通过和tf.placeholder结合在一起，同通过feed_dict机制来选择在每次调用tf.Session.run的时候选择哪种Iterator。\n",
    "\n",
    "它提供了与 reinitilizable iterator 类似的功能，并且在切换数据集的时候不需要在开始的时候初始化iterator。\n",
    "\n",
    "通过tf.data.Iterator.from_string_handle来定义一个 feedable iterator，达到切换数据集的目的。\n",
    "\n",
    "例子如下，和上面的例子类似。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: -10\n",
      "train: -7\n",
      "train: -4\n",
      "val: 0\n",
      "val: 1\n"
     ]
    }
   ],
   "source": [
    "# Define training and validation datasets with the same structure.\n",
    "training_dataset = tf.data.Dataset.range(3).map(lambda x: x + tf.random_uniform([], -10, 10, tf.int64)).repeat()\n",
    "validation_dataset = tf.data.Dataset.range(2)\n",
    "\n",
    "# A feedable iterator is defined by a handle placeholder and its structure. We\n",
    "# could use the `output_types` and `output_shapes` properties of either\n",
    "# `training_dataset` or `validation_dataset` here, because they have\n",
    "# identical structure.\n",
    "handle = tf.placeholder(tf.string, shape=[])\n",
    "iterator = tf.data.Iterator.from_string_handle(handle, training_dataset.output_types, training_dataset.output_shapes)\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "# You can use feedable iterators with a variety of different kinds of iterator\n",
    "# (such as one-shot and initializable iterators).\n",
    "training_iterator = training_dataset.make_one_shot_iterator()\n",
    "validation_iterator = validation_dataset.make_initializable_iterator()\n",
    "\n",
    "sess=tf.Session()\n",
    "\n",
    "# The `Iterator.string_handle()` method returns a tensor that can be evaluated\n",
    "# and used to feed the `handle` placeholder.\n",
    "training_handle = sess.run(training_iterator.string_handle())\n",
    "validation_handle = sess.run(validation_iterator.string_handle())\n",
    "\n",
    "for _ in range(3):\n",
    "    output=sess.run(next_element, feed_dict={handle: training_handle})\n",
    "    print(\"train:\",output)\n",
    "\n",
    "# Run one pass over the validation dataset.\n",
    "sess.run(validation_iterator.initializer)\n",
    "for _ in range(2):\n",
    "    output=sess.run(next_element, feed_dict={handle: validation_handle})\n",
    "    print(\"val:\",output)\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 如果序列不等长，在形成dataset batch时可以使用Dataset.padded_batch方法\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#tf.TensorShape([])     表示长度为单个数字\n",
    "#tf.TensorShape([None]) 表示长度未知的向量\n",
    "    #padded_shapes=(tf.TensorShape([None]),)\n",
    "    #注意，在tf.TensorShape([None])后面不能添加 \",\",因为这里递归嵌套，会认为\",\"后面还有一维数据，\n",
    "    #只是数据格式为 None。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "end\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.range(10)\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "next_element = iterator.get_next()\n",
    "try:\n",
    "    while True:\n",
    "        print(sess.run(iterator.get_next()))\n",
    "except tf.errors.OutOfRangeError:\n",
    "    print(\"end\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[1]\n",
      "[2 2]\n",
      "[3 3 3]\n",
      "[4 4 4 4]\n",
      "[5 5 5 5 5]\n",
      "[6 6 6 6 6 6]\n",
      "[7 7 7 7 7 7 7]\n",
      "[8 8 8 8 8 8 8 8]\n",
      "[9 9 9 9 9 9 9 9 9]\n",
      "end\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.map(lambda x: tf.fill([tf.cast(x, tf.int32)], x))\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "next_element = iterator.get_next()\n",
    "try:\n",
    "    while True:\n",
    "        print(sess.run(iterator.get_next()))\n",
    "except tf.errors.OutOfRangeError:\n",
    "    print(\"end\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0]\n",
      " [1 0]\n",
      " [2 2]]\n",
      "[[3 3 3 0 0]\n",
      " [4 4 4 4 0]\n",
      " [5 5 5 5 5]]\n",
      "[[6 6 6 6 6 6 0 0]\n",
      " [7 7 7 7 7 7 7 0]\n",
      " [8 8 8 8 8 8 8 8]]\n",
      "[[9 9 9 9 9 9 9 9 9]]\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.padded_batch(3, padded_shapes=[None])\n",
    "\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "print(sess.run(next_element))\n",
    "print(sess.run(next_element))\n",
    "print(sess.run(next_element))\n",
    "print(sess.run(next_element))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0]\n",
      "[2 3 0]\n",
      "[4 5 6]\n",
      "[7 8 0]\n",
      "[9 0 0]\n",
      "end\n",
      "[[1 0 0]\n",
      " [2 3 0]]\n",
      "[[4 5 6]\n",
      " [7 8 0]]\n",
      "[[9 0 0]]\n",
      "end\n"
     ]
    }
   ],
   "source": [
    "x = [[1, 0, 0],\n",
    "     [2, 3, 0],\n",
    "     [4, 5, 6],\n",
    "     [7, 8, 0],\n",
    "     [9, 0, 0]]\n",
    "x_new = [np.array(i) for i in x]\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices(x)\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "sess = tf.Session()\n",
    "try:\n",
    "    while True:\n",
    "        print(sess.run(iterator.get_next()))\n",
    "except tf.errors.OutOfRangeError:\n",
    "    print(\"end\")\n",
    "\n",
    "padded_shapes=(tf.TensorShape([None]))\n",
    "dataset = dataset.padded_batch(2, padded_shapes=padded_shapes)#,padding_values=([333,333,333]))\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        print(sess.run(iterator.get_next()))\n",
    "except tf.errors.OutOfRangeError:\n",
    "    print(\"end\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
